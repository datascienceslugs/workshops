{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Data Visualization\n",
    "\n",
    "\n",
    "\n",
    "![logo](logo_thumbnail.png)\n",
    "\n",
    "*Data Science @ SC*\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/datascienceucsc/workshops/blob/master/f2020/data-visualization/statistical_visualization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrivenData Water Table: Problem Statement\n",
    "\n",
    "Using data from Taarifa and the Tanzanian Ministry of Water, can you predict which pumps are functional, which need some repairs, and which don't work at all? This is an intermediate-level practice competition. Predict one of these three classes based on a number of variables about what kind of pump is operating, when it was installed, and how it is managed. A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
    "\n",
    "## Our Goal\n",
    "\n",
    "In this notebook, we'll be doing an initial data exploration, where you will learn about common statistical plots and what to look for when you first start a machine learning competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FEATURES_URL = \"https://drivendata-prod.s3.amazonaws.com/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYVI2LMPSY%2F20201015%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201015T013722Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=75bfa8b86173c1f0fea66245f71d51f1dec45119a0c89bc90a5752ead40db42b\"\n",
    "TRAIN_LABELS_URL = \"https://drivendata-prod.s3.amazonaws.com/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYVI2LMPSY%2F20201015%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201015T013722Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=cfd310526eb2beb7fea303e08379241e2400d99d472644022ffc537c4af876f7\"\n",
    "TEST_FEATURES_URL = \"https://drivendata-prod.s3.amazonaws.com/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYVI2LMPSY%2F20201015%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20201015T013722Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=75bfa8b86173c1f0fea66245f71d51f1dec45119a0c89bc90a5752ead40db42b\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make GET request and write the results to a `.csv` file.\n",
    "\n",
    "**NOTE**: these URLs have expiring credential tokens. If these don't work, go to the [data download](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/data/) \n",
    "page of the competition to get fresh links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(TRAIN_FEATURES_URL)\n",
    "with open(\"train_features.csv\", 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "r = requests.get(TRAIN_LABELS_URL)\n",
    "with open(\"train_labels.csv\", 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "r = requests.get(TEST_FEATURES_URL)\n",
    "with open(\"test_features.csv\", 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data using `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"train_features.csv\")\n",
    "y_train = pd.read_csv(\"train_labels.csv\")\n",
    "X_test = pd.read_csv(\"test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature types\n",
    "\n",
    "View feature descriptions on the [competition page](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/25/#features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_types = X_train.dtypes\n",
    "X_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make lists of categorical and numerical variables. This will be useful for making visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = (X_types\n",
    "    [X_types == \"object\"]\n",
    "    .append(pd.Series({\"region_code\":\"int64\", \"district_code\": \"int64\"}))\n",
    "    .index\n",
    ")\n",
    "\n",
    "X_num = (X_types\n",
    "    [(X_types == \"int64\") | (X_types == \"float64\")]\n",
    "    .drop([\"id\", \"region_code\", \"district_code\"])\n",
    "    .index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is visualization important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First approach to exploring a dataset: taking summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_num].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers don't tell the entire story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Amscombe's quartet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quartet = sns.load_dataset(\"anscombe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics. Look the mean and standard deviation for each of these datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_quartet\n",
    "     [df_quartet[\"dataset\"] == \"I\"]\n",
    "     [[\"x\", \"y\"]]\n",
    "     .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_quartet\n",
    "     [df_quartet[\"dataset\"] == \"II\"]\n",
    "     [[\"x\", \"y\"]]\n",
    "     .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_quartet\n",
    "     [df_quartet[\"dataset\"] == \"III\"]\n",
    "     [[\"x\", \"y\"]]\n",
    "     .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_quartet\n",
    "     [df_quartet[\"dataset\"] == \"IV\"]\n",
    "     [[\"x\", \"y\"]]\n",
    "     .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    x=\"x\", \n",
    "    y=\"y\", \n",
    "    col=\"dataset\", \n",
    "    hue=\"dataset\", \n",
    "    data=df_quartet,\n",
    "    col_wrap=2, \n",
    "    ci=None, \n",
    "    palette=\"rocket\", \n",
    "    height=4,\n",
    "    scatter_kws={\"s\": 50, \"alpha\": 0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Datasaurus Dozen\n",
    "\n",
    "Even more extreme example where all the summary statistics are the same!\n",
    "\n",
    "![Datasaurus dozen](https://d2f99xq7vri1nk.cloudfront.net/AllDinosGrey_1.png)\n",
    "\n",
    "*Justin Matejka, George Fitzmaurice, Autodesk Research, 2017* | [link](https://www.autodesk.com/research/publications/same-stats-different-graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical plots for the DrivenData Water Table competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll visualize different the data from the DrivenData Water Table competition. We'd like to get a feel for our data before we dive right in to modeling.\n",
    "\n",
    "First, we'll run Pandas `infer_objects`, which tries to infer what data type each columns should be (int, string, etc). In pandas, the data type are called `dtypes`. Then, we'll run `.head(n)` to look at the first `n` rows of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.infer_objects()\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Missing Values\n",
    "\n",
    "Real world datasets are not always perfect, in fact, they very often have missing entries. We'd like to know how many entires are missing from each column (to determine if there is enough data to use), the number of rows with missing data, and the percentage of the missing data. If there is very little missing data, we could potentially drop the rows with any missing value. However, if there is not, we'll have to think about how we can impute the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = X_train.isnull().sum()\n",
    "px.bar(x=missing_count.index, y=missing_count.values, title='Number of Missing Values for Each Column').show()\n",
    "px.bar(x=missing_count.index, y=missing_count.values / X_train.shape[0]*100, title='Percentage of Missing Values in Each Column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Distributions\n",
    "\n",
    "As you can see from our data above, we only have a few columns that are numeric. For the non-numeric columns, we can use Pandas `.value_counts()` to get the number of rows with each unique value. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['funder'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives us the number of rows with the Government of Tanzania as the funder, etc. Below, we show the distribution of `gps_height`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(X_train, x=\"gps_height\", nbins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize the rest of the columns. If they aren't numeric, we'll visualize their `.value_counts()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if np.issubdtype(X_train[col].dtype, np.number):\n",
    "        px.histogram(X_train, x=col).show()\n",
    "    else:\n",
    "        valcounts = X_train[col].value_counts()\n",
    "        px.histogram(x=valcounts.index, y=valcounts.values).show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Numeric | Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Numeric | Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Categorical | Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Many Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Miscalleneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Summarizing relations\n",
    "\n",
    "Here, we visualize Pearson correlation between all numeric columns. Obviously, take this with a grain of salt. Not all these columns are numerically representative of some distribution, and hence the correlation won't have much meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(X_train.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Data transformations\n",
    "\n",
    "Log or polar transformations may reveal extra structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
